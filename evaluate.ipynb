{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOR ðŸš€ 0aa36cd torch 1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090, 24268.3125MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/20221011/0/dataset.yaml\n",
      "data/processed/20230705/0/dataset.yaml\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/processed/20230705/0/labels/valid.cache' images and labels... 132 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.07it/s]\n",
      "YOLOR ðŸš€ 0aa36cd torch 1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090, 24268.3125MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/20221011/1/dataset.yaml\n",
      "data/processed/20230705/1/dataset.yaml\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/processed/20230705/1/labels/valid.cache' images and labels... 132 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.04it/s]\n",
      "YOLOR ðŸš€ 0aa36cd torch 1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090, 24268.3125MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/20221011/2/dataset.yaml\n",
      "data/processed/20230705/2/dataset.yaml\n",
      "Fusing layers... \n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "RepConv.fuse_repvgg_block\n",
      "IDetect.fuse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'data/processed/20230705/2/labels/valid.cache' images and labels... 132 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:00<?, ?it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from mymake.valid import valid\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "project=\"20221011\"\n",
    "train_project=\"20230705\"\n",
    "# project=\"20230705\"\n",
    "# train_project=\"20221011\"\n",
    "numbers=3\n",
    "\n",
    "\n",
    "for number in range(numbers):\n",
    "    number=str(number)\n",
    "    train_data=\"data/processed/{}/{}/dataset.yaml\".format(project,number) \n",
    "    # train_data=None\n",
    "    class MyClass:\n",
    "        def __init__(self,project,number,train_project):\n",
    "            self.weights='runs/train/{}/{}/weights/epoch_500.pt'.format(project,number)#helpp='model.pt path(s)')\n",
    "            self.data=\"data/processed/{}/{}/dataset.yaml\".format(train_project,number)#helpp='*.data path')\n",
    "            self.batch_size=16#helpp='size of each image batch')\n",
    "            self.img_size=[320]#helpp='inference size (pixels)')\n",
    "            self.conf_thres=0.5#helpp='object confidence threshold')\n",
    "            self.iou_thres=0.45#helpp='IOU threshold for NMS')\n",
    "            self.conf_result=0.5\n",
    "            self.iou_result=0.5\n",
    "            save_inc_img=False\n",
    "            self.task='val'#helpp='train, val, test, speed or study')\n",
    "            self.device=\"0\"#helpp='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "            self.single_cls=None#helpp='treat as single-class dataset')\n",
    "            self.augment=None#helpp='augmented inference')\n",
    "            self.verbose=None#helpp='report mAP by class')\n",
    "            self.save_txt=False #helpp='save results to *.txt')\n",
    "            self.save_hybrid=False #helpp='save label+prediction hybrid results to *.txt')\n",
    "            self.save_conf=None#helpp='save confidences in --save-txt labels')\n",
    "            self.save_json=None#helpp='save a cocoapi-compatible JSON results file')\n",
    "            self.project='runs/valid/'#helpp='save to project/name')\n",
    "            if train_project!=None:\n",
    "                self.name=\"{}/{}/{}\".format(project,number,train_project)\n",
    "            else:\n",
    "                self.name=\"{}/{}\".format(project,number) #helpp='save to project/name')\n",
    "            self.exist_ok=True#helpp='existing project/name ok, do not increment')\n",
    "            self.no_trace=None#helpp='don`t trace model')\n",
    "            self.v5_metric=None#helpp='assume maximum recall as 1.0 in AP calculation')\n",
    "            self.trace=None\n",
    "            self.plots=True\n",
    "            self.model=None\n",
    "            self.half_precision=True\n",
    "            self.wandb_logger=None\n",
    "            self.compute_loss=None\n",
    "            self.save_inc_img=False\n",
    "            self.save_result=True\n",
    "\n",
    "    opt=MyClass(project,number,train_project)  \n",
    "    \n",
    "    accuracy=valid(opt,opt.weights,train_data,opt.save_result)\n",
    "\n",
    "    with open(str(Path(opt.project)/opt.name/'accuracy.txt'), 'w') as f:\n",
    "        f.write(str(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
