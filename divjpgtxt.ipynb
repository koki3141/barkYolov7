{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import yaml\n",
    "from mymake.datasetformat import mkdir,yolov7Dataset,yolov7Yaml\n",
    "\n",
    "from os import path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self,folderName,depths,numOfDatasets):\n",
    "        \n",
    "        self.originalPath=Path(\"data\")/\"original\"/folderName\n",
    "        self.outputPath=Path(\"data\")/\"processed\"/folderName\n",
    "        \n",
    "        folderDepths=len(self.originalPath.parts)+depths\n",
    "        self.classPaths=[i for i in list(self.originalPath.glob('**')) if len(i.parts)==folderDepths]\n",
    "        self.classNames=[i.name for i in self.classPaths]\n",
    "        self.classCounts=Data.check(self)\n",
    "        self.minCount=min(self.classCounts)\n",
    "        \n",
    "        \n",
    "        self.minClassName=self.classNames[self.classCounts.index(min(self.classCounts))]\n",
    "        self.numOfDatasets=numOfDatasets\n",
    "        \n",
    "        \n",
    "        Data.checkExist(self.originalPath)\n",
    "        Data.dataAnalysis(self)\n",
    "        \n",
    "        # self.minCount=131\n",
    "        \n",
    "    def checkExist(self):  \n",
    "        assert self.exists(), f'\"{str(self)}\" does not exist'\n",
    "    \n",
    "\n",
    "        \n",
    "    def check(self):\n",
    "        imagefileCounts=[len(list(path.glob('**/*.jpg'))) for path in self.classPaths]\n",
    "        textfileCounts=[len(list(path.glob('**/*.txt'))) for path in self.classPaths]\n",
    "        if imagefileCounts == textfileCounts:\n",
    "            return textfileCounts\n",
    "        \n",
    "        print(imagefileCounts)\n",
    "        print(textfileCounts)\n",
    "        assert False,'imageFile and textFile count do not match'    \n",
    "    \n",
    "    def dataAnalysis(self):\n",
    "        display(pd.DataFrame(self.classCounts, index=self.classNames,columns=['number of sheets']))\n",
    "    \n",
    "    def divTrainValid(self):\n",
    "        div0=int(self.minCount*2/3)\n",
    "        div1=int(self.minCount)\n",
    "        \n",
    "        mkdir(self.outputPath)\n",
    "        for num in range(self.numOfDatasets):\n",
    "            def mkdirFolder(outputPathNum):\n",
    "                definePath=[Path('images')/'train',Path('labels')/'train',Path('images')/'valid',Path('labels')/'valid']\n",
    "                savePath = [str(outputPathNum/path) for path in definePath]\n",
    "                np.vectorize(mkdir)(savePath)\n",
    "                return savePath\n",
    "            \n",
    "            outputPathNum=self.outputPath/str(num)\n",
    "            \n",
    "            mkdir(outputPathNum)\n",
    "            yolov7Yaml(outputPathNum,self.classNames)\n",
    "            savePath=mkdirFolder(outputPathNum)\n",
    "            for classId,classPath in enumerate(self.classPaths):\n",
    "\n",
    "                jpg_files=np.array(sorted(classPath.glob(\"**/*.jpg\")),dtype=str)\n",
    "                txt_files=np.array(sorted(classPath.glob(\"**/*.txt\")),dtype=str)\n",
    "                \n",
    "                random_index=random.sample(range(len(jpg_files)),k=self.minCount)\n",
    "                train_index=random_index[:div0]\n",
    "                valid_index=random_index[div0:div1]\n",
    "                \n",
    "                train_jpg_files=jpg_files[train_index]\n",
    "                valid_jpg_files=jpg_files[valid_index]\n",
    "                train_txt_files=txt_files[train_index]\n",
    "                valid_txt_files=txt_files[valid_index]\n",
    "                \n",
    "                yolov7Dataset(train_jpg_files,train_txt_files,valid_jpg_files,valid_txt_files,savePath,classId)\n",
    "    def mkCommand(self):\n",
    "        epochs=500\n",
    "        batch_size=16\n",
    "        img_size=320\n",
    "        save_period=100\n",
    "        weight=\"yolov7/weights/yolov7_training.pt\"\n",
    "        \n",
    "        command=\"python train.py --device 0 --epochs {0} --batch-size {1} --img {2} --data {3}/dataset.yaml --weights {4} --name {3} --save_period {5};\"\n",
    "\n",
    "        \n",
    "        for num in range(self.numOfDatasets):\n",
    "            print(command.format(epochs,batch_size,img_size,str(Path(self.outputPath.name)/str(num)),weight,str(save_period)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20221011\n",
      "20230705\n",
      "8ahkmnuyy\n"
     ]
    }
   ],
   "source": [
    "original_path=Path(\"data\")/\"original\"\n",
    "datasets=list(original_path.glob(\"*\"))\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of sheets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>measa</th>\n",
       "      <td>1183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kizinn</th>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honnsugi</th>\n",
       "      <td>2734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yabukuguri</th>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uraseruba</th>\n",
       "      <td>1036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninnzinnba</th>\n",
       "      <td>2036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>akaba</th>\n",
       "      <td>3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yamaguti</th>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            number of sheets\n",
       "measa                   1183\n",
       "kizinn                  2099\n",
       "honnsugi                2734\n",
       "yabukuguri              2186\n",
       "uraseruba               1036\n",
       "ninnzinnba              2036\n",
       "akaba                   3151\n",
       "yamaguti                2070"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --device 0 --epochs 500 --batch-size 16 --img 320 --data 8ahkmnuyy/0/dataset.yaml --weights yolov7/weights/yolov7_training.pt --name 8ahkmnuyy/0 --save_period 100;\n",
      "python train.py --device 0 --epochs 500 --batch-size 16 --img 320 --data 8ahkmnuyy/1/dataset.yaml --weights yolov7/weights/yolov7_training.pt --name 8ahkmnuyy/1 --save_period 100;\n",
      "python train.py --device 0 --epochs 500 --batch-size 16 --img 320 --data 8ahkmnuyy/2/dataset.yaml --weights yolov7/weights/yolov7_training.pt --name 8ahkmnuyy/2 --save_period 100;\n",
      "python train.py --device 0 --epochs 500 --batch-size 16 --img 320 --data 8ahkmnuyy/3/dataset.yaml --weights yolov7/weights/yolov7_training.pt --name 8ahkmnuyy/3 --save_period 100;\n",
      "python train.py --device 0 --epochs 500 --batch-size 16 --img 320 --data 8ahkmnuyy/4/dataset.yaml --weights yolov7/weights/yolov7_training.pt --name 8ahkmnuyy/4 --save_period 100;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folderName=\"8ahkmnuyy\"\n",
    "\n",
    "\n",
    "folderDepth=1\n",
    "numOfDatasets=5\n",
    "\n",
    "subData=Data(folderName,folderDepth,numOfDatasets)\n",
    "\n",
    "\n",
    "subData.mkCommand()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
